

## ğŸ›°ï¸ Satellite Imageryâ€“Based Property Valuation

A machine learning project that estimates property prices by combining **tabular real-estate data** with **satellite imageryâ€“derived geospatial context**, using a clean, leakage-safe, production-style pipeline.

---

## ğŸ“Œ Project Overview

Traditional property valuation models rely only on tabular features such as size, location codes, or amenities.  
This project enhances valuation by incorporating **satellite imagery context** (via Mapbox) to capture spatial signals such as surroundings, density, and locality characteristics.

### Key Highlights
- Clean separation of **data fetching**, **preprocessing**, **training**, and **inference**
- Sample vs full dataset execution support
- Leakage-safe evaluation
- Reproducible pipeline with clear artifact management
- Ready for portfolio, interviews, and extension

---

## ğŸ—ï¸ High-Level Architecture

```

Satellite Imagery (Conceptual)
            â†“
Spatial Context Understanding
            â†“
Engineered Geospatial Features
            â†“
Tabular Feature Set
            â†“
Random Forest Regressor
            â†“
Predicted Property Price

```

---

## ğŸ“ Repository Structure

```

SATELLITE_PROPERTY_VALUATION/
â”‚
â”œâ”€â”€ data/                        # Structured tabular datasets
â”‚   â”œâ”€â”€ train.xlsx               # Original training dataset
â”‚   â”œâ”€â”€ test.xlsx                # Original test dataset
â”‚   â”œâ”€â”€ X_features_full.csv      # Engineered feature matrix (full data)
â”‚   â””â”€â”€ y_target_full.csv        # Target variable (property prices)
â”‚
â”œâ”€â”€ images/                      # Satellite imagery data
â”‚   â”œâ”€â”€ train/                   # Full training images
â”‚   â”œâ”€â”€ test/                    # Test images for inference
â”‚   â””â”€â”€ train_sample/            # Small image subset for experiments
â”‚
â”œâ”€â”€ data_fetcher.py              # Image â†” tabular data mapping logic
â”‚
â”œâ”€â”€ preprocessing.ipynb          # Data cleaning & feature engineering
â”œâ”€â”€ model_training.ipynb         # Model training, validation & evaluation
â”‚
â”œâ”€â”€ predicted_vs_actual_training_data.csv
â”‚                                 # Actual vs predicted values (training set)
â”‚
â”œâ”€â”€ submission.csv               # Final model predictions (test set)
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ .gitignore                   # Files & folders excluded from version control
â””â”€â”€ README.md                    # Project documentation


```

---

## ğŸš« What Is NOT Included (and Why)

To keep the repository **clean, lightweight, and secure**, the following are intentionally excluded:

### âŒ `images/` contents
- Satellite images are **large and auto-generated**
- They are fetched dynamically using `data_fetcher.py`
- Including them would bloat the repository

âœ”ï¸ **Solution:**  
An empty `images/` folder is kept so the code knows where to save images at runtime.

---

### âŒ `venv/` (Virtual Environment)
- Platform-specific
- Extremely large
- Not portable across systems

âœ”ï¸ **Solution:**  
Dependencies are listed in `requirements.txt`

---

### âŒ API Keys / Secrets
- Never commit credentials to GitHub

âœ”ï¸ **Solution:**  
Use environment variables (explained below)

---

## ğŸ“„ `.gitignore` (Important)

The `.gitignore` file is **required and should be uploaded**.

It prevents:
- accidental uploads of large files
- leaking credentials
- committing virtual environments

Example exclusions:
```

venv/
images/*
**pycache**/
.env

````

---

## âš™ï¸ Setup Instructions (Step-by-Step)

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/Satellite_Property_Valuation.git
cd Satellite_Property_Valuation
````

---

### 2ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv venv
```

Activate it:

* **Windows**

```bash
venv\Scripts\activate
```

* **macOS / Linux**

```bash
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Set Environment Variables (Mapbox API)

Create an environment variable:

**Windows (PowerShell):**

```powershell
setx MAPBOX_API_KEY "your_api_key_here"
```

**macOS / Linux:**

```bash
export MAPBOX_API_KEY="your_api_key_here"
```

---

### 5ï¸âƒ£ Ensure Folder Structure Exists

Make sure this folder exists (even if empty):

```
images/
```

Satellite images will be automatically saved here when running the data fetcher.

---

## â–¶ï¸ How to Run the Project

### Step 1 â€” Fetch Satellite Images

```bash
python src/data_fetcher.py
```

This will:

* Read coordinates
* Download satellite images
* Save them into `images/`

---

### Step 2 â€” Preprocessing & Feature Engineering

Open and run:

```
notebooks/preprocessing.ipynb
```

Supports:

* Sample mode (fast experimentation)
* Full dataset mode (final training)

---

### Step 3 â€” Model Training & Evaluation

Run:

```
notebooks/model_training.ipynb
```

Outputs:

* Trained model
* Evaluation metrics
* `predicted_vs_actual_*.csv` for error analysis

---

### Step 4 â€” Test Inference (No Leakage)

Run:

```
notebooks/test_inference.ipynb
```

Generates:

```
submission.csv
```

(This is the final prediction file.)

---

## ğŸ“Š Evaluation Artifacts

`predicted_vs_actual_full.csv` contains:

* actual price
* predicted price
* signed error
* absolute error

This file is **for analysis only**, not submission.

---

## ğŸ”’ Data Leakage Safety

âœ”ï¸ Test data is **never used** in:

* preprocessing fitting
* feature selection
* model training

âœ”ï¸ Test data is used **only once** for inference.

---

## ğŸš€ Future Improvements

* CNN-based satellite image embeddings
* Gradient boosting models
* Temporal price modeling
* Model ensembling
* Deployment via API

---

## ğŸ‘¤ Author

**Hardik Gautam**
Data Science & Machine Learning Enthusiast
ğŸ“ India | ğŸŒ Open to global opportunities

---

## â­ Final Note

This repository is structured to reflect **real-world ML engineering practices**, not just experimentation.
Every inclusion and exclusion is **intentional** and explained for clarity and reproducibility.

---
